{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II: Model Building\n",
    "\n",
    "Here you try your hand at model building to predict appointment no shows.\n",
    "\n",
    "### Preprocessing\n",
    "\n",
    "Package 'noshow_lib' now includes code to carry out preprocessing steps from part I. Here's how to use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import noshow_lib.util as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, it includes a dictionary used for configuring path and file names\n",
    "used through the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature_pipeline_file': 'feature_pipeline.pkl',\n",
       " 'labels_pipeline_file': 'labels_pipeline.pkl',\n",
       " 'objstore_path': 'objects',\n",
       " 'processed_data_path': 'processed_data',\n",
       " 'raw_data_csv': 'KaggleV2-May-2016.csv',\n",
       " 'raw_data_path': 'data',\n",
       " 'test_csv': 'test_set.csv',\n",
       " 'train_csv': 'train_set.csv'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.file_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`feature_pipeline_file`: file storing the preprocessing pipeline used for preparing the feature matrix\n",
    "\n",
    "`labels_pipeline_file`: file storing the preprocessing pipeline used for\n",
    "preparing labels\n",
    "\n",
    "`objstore_path`: directory to store python objects to disk\n",
    "\n",
    "`processed_data_path`: directory containing processed data\n",
    "\n",
    "`raw_data_csv`: name of the csv download from Kaggle\n",
    "\n",
    "`raw_data_path`: directory containing raw data\n",
    "\n",
    "`test_csv`: name of csv file containing test set\n",
    "\n",
    "`train_csv`: name of csv file containing train set\n",
    "\n",
    "You can change these paths and names to suit your project directory structure if you need so. E.g.,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_config = utils.file_config\n",
    "#config['raw_data_path'] = \"some_other_directory\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step is to create train test sets. Code is in file `noshow_lib/util.py` function `make_train_test_sets`. You\n",
    "can edit that function as needed to include your own part I code if you so desire. The result will be to \n",
    "create files `train_set.csv` and `test_set.csv` in your `processed_data` directory (unless you change any of the entries in the configuration directory as above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ONLY NEED TO RUN THIS STEP ONCE (switch this to True to run it)\n",
    "RUN_MAKE_TRAIN_TEST_FILES = True\n",
    "if RUN_MAKE_TRAIN_TEST_FILES:\n",
    "    utils.make_train_test_sets(config=file_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to fit the preprocessing pipelines. This is done in file `noshow_lib/preprocess.py`. Again you can edit code as needed in that file to incorporate your part I solution as you wish. The result will be to create files `feature_pipeline.pkl` and `labels_pipeline.pkl` containing the fit preprocessing pipelines we can then use to preprocess data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/_encoders.py:326: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)]'.\n",
      "  warnings.warn(msg, DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/_encoders.py:326: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)]'.\n",
      "  warnings.warn(msg, DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import noshow_lib.preprocess as preprocess\n",
    "\n",
    "# ONLY NEED TO RUN THIS STEP ONCE\n",
    "RUN_FIT_PREPROCESSING = True\n",
    "if RUN_FIT_PREPROCESSING:\n",
    "    preprocess.fit_save_pipelines(config=file_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, once we do that, we can get a training matrix and labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X, train_y = preprocess.load_train_data(config=file_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90526, 101)\n",
      "(90526,)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building\n",
    "\n",
    "Using `sklearn` fit:\n",
    "    - DecisionTree classifier\n",
    "    - RandomForest classifier\n",
    "    - Linear SVM classifier\n",
    "    - SVM with Radial Basis Kernel classifier\n",
    "    \n",
    "Use default parameters for now.\n",
    "Using 10-fold cross validation report both accuracy and AUC for each of the above four models.\n",
    "\n",
    "QUESTION: Should you use accuracy or AUC for this task as a performance metric?\n",
    "\n",
    "_ANSWER HERE_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All 4 classifiers seem pretty bad. The original dataset had about 79% of patients showing up for appointments. Having a model that just predicts false (no shows) for all patients would do better than these models. Similarly the AUC values are bad, close to 0.5, meaning just making random guesses would work better.  \n",
    "\n",
    "I would probably choose an AUC here. It would give me the info needed to pick a threshold that would maximize my TPR. In this case it would allow doctors to double book people who they suspect will be no shows. Sure the FPR would be higher, but that just means people will have to wait a bit longer to see the doctor, which already happens these days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build your models here\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Decision Tree\n",
    "scores_acc = cross_val_score(DecisionTreeClassifier(), train_X, train_y, cv=10, scoring='accuracy')\n",
    "scores_auc = cross_val_score(DecisionTreeClassifier(), train_X, train_y, cv=10, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.74273721  0.74185353  0.74240583  0.74229537  0.73434221  0.73831879\n",
      "  0.74038886  0.73254529  0.74480778  0.73077773]\n",
      "[ 0.58589999  0.58666476  0.58376334  0.58661971  0.57711156  0.57962615\n",
      "  0.58986953  0.57428182  0.58709045  0.5765555 ]\n"
     ]
    }
   ],
   "source": [
    "print scores_acc\n",
    "print scores_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Random Forrest\n",
    "scores_acc = cross_val_score(RandomForestClassifier(), train_X, train_y, cv=10, scoring='accuracy')\n",
    "scores_auc = cross_val_score(RandomForestClassifier(), train_X, train_y, cv=10, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.77808461  0.77698001  0.77786369  0.77631724  0.77554402  0.77289296\n",
      "  0.77872293  0.77364118  0.77574017  0.77121078]\n",
      "[ 0.70032626  0.69681271  0.68820308  0.69846838  0.69151386  0.69314235\n",
      "  0.68807828  0.68562313  0.69791322  0.6874412 ]\n"
     ]
    }
   ],
   "source": [
    "print scores_acc\n",
    "print scores_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Linear SVM\n",
    "scores_acc = cross_val_score(LinearSVC(), train_X, train_y, cv=10, scoring='accuracy')\n",
    "scores_auc = cross_val_score(LinearSVC(), train_X, train_y, cv=10, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.79608969  0.79509555  0.79675246  0.79597923  0.79586877  0.796642\n",
      "  0.79595669  0.79750331  0.79639859  0.79617764]\n",
      "[ 0.66531013  0.66873271  0.67112264  0.66972307  0.6617669   0.67428816\n",
      "  0.66172633  0.66432048  0.67135942  0.66482576]\n"
     ]
    }
   ],
   "source": [
    "print scores_acc\n",
    "print scores_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Linear SVM with Radial-basis function kernel \n",
    "scores_acc = cross_val_score(SVC(), train_X, train_y, cv=10, scoring='accuracy')\n",
    "scores_auc = cross_val_score(SVC(), train_X, train_y, cv=10, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.79807799  0.79807799  0.79807799  0.79807799  0.79807799  0.79807799\n",
      "  0.79805568  0.79805568  0.79805568  0.79805568]\n",
      "[ 0.5663538   0.56630337  0.62730793  0.60272141  0.60423637  0.56051229\n",
      "  0.57808653  0.55330968  0.60036892  0.56649478]\n"
     ]
    }
   ],
   "source": [
    "print scores_acc\n",
    "print scores_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Tuning\n",
    "\n",
    "Based on the above, choose two methods and fit a tuned model:\n",
    "    - use 5-fold cross validation for model selection\n",
    "    - use 10-fold cross validation for model assessment (based on appropriate performance metric)\n",
    "\n",
    "Report estimated performance for both tuned classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:  2.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'loss': ('squared_hinge', 'hinge'), 'C': (10, 1, 0.1, 0.01)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {'loss': ('squared_hinge','hinge'), 'C': (10,1,0.1,0.01)}\n",
    "gd = GridSearchCV(LinearSVC(), param_grid=params, scoring='roc_auc', fit_params=None, cv=5, verbose=1)\n",
    "gd.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.811248</td>\n",
       "      <td>0.007828</td>\n",
       "      <td>0.668398</td>\n",
       "      <td>0.671990</td>\n",
       "      <td>10</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>{u'loss': u'squared_hinge', u'C': 10}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.663288</td>\n",
       "      <td>0.667183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.668927</td>\n",
       "      <td>0.671447</td>\n",
       "      <td>0.667954</td>\n",
       "      <td>0.677146</td>\n",
       "      <td>0.670582</td>\n",
       "      <td>0.672112</td>\n",
       "      <td>0.075047</td>\n",
       "      <td>0.001348</td>\n",
       "      <td>0.002808</td>\n",
       "      <td>0.003163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.815341</td>\n",
       "      <td>0.007251</td>\n",
       "      <td>0.510132</td>\n",
       "      <td>0.507549</td>\n",
       "      <td>10</td>\n",
       "      <td>hinge</td>\n",
       "      <td>{u'loss': u'hinge', u'C': 10}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.502129</td>\n",
       "      <td>0.493033</td>\n",
       "      <td>...</td>\n",
       "      <td>0.505996</td>\n",
       "      <td>0.505486</td>\n",
       "      <td>0.531292</td>\n",
       "      <td>0.531803</td>\n",
       "      <td>0.487819</td>\n",
       "      <td>0.488557</td>\n",
       "      <td>0.017780</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.015515</td>\n",
       "      <td>0.016075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.882521</td>\n",
       "      <td>0.007307</td>\n",
       "      <td>0.666957</td>\n",
       "      <td>0.670631</td>\n",
       "      <td>1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>{u'loss': u'squared_hinge', u'C': 1}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.666800</td>\n",
       "      <td>0.670533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.667939</td>\n",
       "      <td>0.670219</td>\n",
       "      <td>0.661847</td>\n",
       "      <td>0.671380</td>\n",
       "      <td>0.667983</td>\n",
       "      <td>0.670012</td>\n",
       "      <td>0.225107</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.002785</td>\n",
       "      <td>0.000504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.791430</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>0.481121</td>\n",
       "      <td>0.484243</td>\n",
       "      <td>1</td>\n",
       "      <td>hinge</td>\n",
       "      <td>{u'loss': u'hinge', u'C': 1}</td>\n",
       "      <td>7</td>\n",
       "      <td>0.468118</td>\n",
       "      <td>0.463067</td>\n",
       "      <td>...</td>\n",
       "      <td>0.534152</td>\n",
       "      <td>0.539991</td>\n",
       "      <td>0.506490</td>\n",
       "      <td>0.513383</td>\n",
       "      <td>0.427767</td>\n",
       "      <td>0.431870</td>\n",
       "      <td>0.364969</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.036377</td>\n",
       "      <td>0.038150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.328234</td>\n",
       "      <td>0.007234</td>\n",
       "      <td>0.667026</td>\n",
       "      <td>0.670648</td>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>{u'loss': u'squared_hinge', u'C': 0.1}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.666831</td>\n",
       "      <td>0.670541</td>\n",
       "      <td>...</td>\n",
       "      <td>0.668017</td>\n",
       "      <td>0.670237</td>\n",
       "      <td>0.661900</td>\n",
       "      <td>0.671395</td>\n",
       "      <td>0.668056</td>\n",
       "      <td>0.670040</td>\n",
       "      <td>0.858621</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.002802</td>\n",
       "      <td>0.000500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.095410</td>\n",
       "      <td>0.007349</td>\n",
       "      <td>0.500251</td>\n",
       "      <td>0.495067</td>\n",
       "      <td>0.1</td>\n",
       "      <td>hinge</td>\n",
       "      <td>{u'loss': u'hinge', u'C': 0.1}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.529026</td>\n",
       "      <td>0.528360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.454171</td>\n",
       "      <td>0.458519</td>\n",
       "      <td>0.543150</td>\n",
       "      <td>0.534125</td>\n",
       "      <td>0.504868</td>\n",
       "      <td>0.494887</td>\n",
       "      <td>0.393876</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.033840</td>\n",
       "      <td>0.032369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.381750</td>\n",
       "      <td>0.007277</td>\n",
       "      <td>0.667554</td>\n",
       "      <td>0.670833</td>\n",
       "      <td>0.01</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>{u'loss': u'squared_hinge', u'C': 0.01}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.667211</td>\n",
       "      <td>0.670731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.668487</td>\n",
       "      <td>0.670431</td>\n",
       "      <td>0.662314</td>\n",
       "      <td>0.671560</td>\n",
       "      <td>0.668681</td>\n",
       "      <td>0.670225</td>\n",
       "      <td>0.008448</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.002903</td>\n",
       "      <td>0.000494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.245132</td>\n",
       "      <td>0.007259</td>\n",
       "      <td>0.471850</td>\n",
       "      <td>0.472563</td>\n",
       "      <td>0.01</td>\n",
       "      <td>hinge</td>\n",
       "      <td>{u'loss': u'hinge', u'C': 0.01}</td>\n",
       "      <td>8</td>\n",
       "      <td>0.382245</td>\n",
       "      <td>0.384877</td>\n",
       "      <td>...</td>\n",
       "      <td>0.545855</td>\n",
       "      <td>0.547132</td>\n",
       "      <td>0.526312</td>\n",
       "      <td>0.525902</td>\n",
       "      <td>0.446775</td>\n",
       "      <td>0.441995</td>\n",
       "      <td>0.037879</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.058806</td>\n",
       "      <td>0.058518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score param_C  \\\n",
       "0       9.811248         0.007828         0.668398          0.671990      10   \n",
       "1       7.815341         0.007251         0.510132          0.507549      10   \n",
       "2       9.882521         0.007307         0.666957          0.670631       1   \n",
       "3       1.791430         0.007300         0.481121          0.484243       1   \n",
       "4       3.328234         0.007234         0.667026          0.670648     0.1   \n",
       "5       1.095410         0.007349         0.500251          0.495067     0.1   \n",
       "6       0.381750         0.007277         0.667554          0.670833    0.01   \n",
       "7       0.245132         0.007259         0.471850          0.472563    0.01   \n",
       "\n",
       "      param_loss                                   params  rank_test_score  \\\n",
       "0  squared_hinge    {u'loss': u'squared_hinge', u'C': 10}                1   \n",
       "1          hinge            {u'loss': u'hinge', u'C': 10}                5   \n",
       "2  squared_hinge     {u'loss': u'squared_hinge', u'C': 1}                4   \n",
       "3          hinge             {u'loss': u'hinge', u'C': 1}                7   \n",
       "4  squared_hinge   {u'loss': u'squared_hinge', u'C': 0.1}                3   \n",
       "5          hinge           {u'loss': u'hinge', u'C': 0.1}                6   \n",
       "6  squared_hinge  {u'loss': u'squared_hinge', u'C': 0.01}                2   \n",
       "7          hinge          {u'loss': u'hinge', u'C': 0.01}                8   \n",
       "\n",
       "   split0_test_score  split0_train_score       ...         split2_test_score  \\\n",
       "0           0.663288            0.667183       ...                  0.668927   \n",
       "1           0.502129            0.493033       ...                  0.505996   \n",
       "2           0.666800            0.670533       ...                  0.667939   \n",
       "3           0.468118            0.463067       ...                  0.534152   \n",
       "4           0.666831            0.670541       ...                  0.668017   \n",
       "5           0.529026            0.528360       ...                  0.454171   \n",
       "6           0.667211            0.670731       ...                  0.668487   \n",
       "7           0.382245            0.384877       ...                  0.545855   \n",
       "\n",
       "   split2_train_score  split3_test_score  split3_train_score  \\\n",
       "0            0.671447           0.667954            0.677146   \n",
       "1            0.505486           0.531292            0.531803   \n",
       "2            0.670219           0.661847            0.671380   \n",
       "3            0.539991           0.506490            0.513383   \n",
       "4            0.670237           0.661900            0.671395   \n",
       "5            0.458519           0.543150            0.534125   \n",
       "6            0.670431           0.662314            0.671560   \n",
       "7            0.547132           0.526312            0.525902   \n",
       "\n",
       "   split4_test_score  split4_train_score  std_fit_time  std_score_time  \\\n",
       "0           0.670582            0.672112      0.075047        0.001348   \n",
       "1           0.487819            0.488557      0.017780        0.000095   \n",
       "2           0.667983            0.670012      0.225107        0.000146   \n",
       "3           0.427767            0.431870      0.364969        0.000178   \n",
       "4           0.668056            0.670040      0.858621        0.000193   \n",
       "5           0.504868            0.494887      0.393876        0.000078   \n",
       "6           0.668681            0.670225      0.008448        0.000147   \n",
       "7           0.446775            0.441995      0.037879        0.000212   \n",
       "\n",
       "   std_test_score  std_train_score  \n",
       "0        0.002808         0.003163  \n",
       "1        0.015515         0.016075  \n",
       "2        0.002785         0.000504  \n",
       "3        0.036377         0.038150  \n",
       "4        0.002802         0.000500  \n",
       "5        0.033840         0.032369  \n",
       "6        0.002903         0.000494  \n",
       "7        0.058806         0.058518  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(gd.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][ 0.66699026  0.6694093   0.67200586  0.67063348  0.66291922  0.6747928\n",
      "  0.66283079  0.6656185   0.67354866  0.66719084]\n"
     ]
    }
   ],
   "source": [
    "# tune your models here\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Linear SVM\n",
    "scores_linsvm = cross_val_score(LinearSVC(C=10,loss='squared_hinge',verbose=1), train_X, train_y, cv=10, scoring='roc_auc')\n",
    "print scores_linsvm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No real improvement here. Using a default Linear SVM or a modified model, with a bigger cost fuction has almost no effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed: 35.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_estimators': (10, 100, 1000), 'criterion': ('gini', 'entropy')},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {'criterion': ('gini','entropy'), 'n_estimators': (10,100,1000)}\n",
    "gd1 = GridSearchCV(RandomForestClassifier(), param_grid=params, scoring='roc_auc', cv=5, verbose=1)\n",
    "gd1.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.665466</td>\n",
       "      <td>0.054109</td>\n",
       "      <td>0.688218</td>\n",
       "      <td>0.994487</td>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>{u'n_estimators': 10, u'criterion': u'gini'}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.688483</td>\n",
       "      <td>0.994330</td>\n",
       "      <td>...</td>\n",
       "      <td>0.688704</td>\n",
       "      <td>0.994383</td>\n",
       "      <td>0.685547</td>\n",
       "      <td>0.994665</td>\n",
       "      <td>0.683818</td>\n",
       "      <td>0.994449</td>\n",
       "      <td>0.019514</td>\n",
       "      <td>0.000617</td>\n",
       "      <td>0.003654</td>\n",
       "      <td>0.000129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.232890</td>\n",
       "      <td>0.483897</td>\n",
       "      <td>0.718327</td>\n",
       "      <td>0.998192</td>\n",
       "      <td>gini</td>\n",
       "      <td>100</td>\n",
       "      <td>{u'n_estimators': 100, u'criterion': u'gini'}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.719425</td>\n",
       "      <td>0.998143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.716627</td>\n",
       "      <td>0.998194</td>\n",
       "      <td>0.715484</td>\n",
       "      <td>0.998244</td>\n",
       "      <td>0.719147</td>\n",
       "      <td>0.998120</td>\n",
       "      <td>0.121571</td>\n",
       "      <td>0.006928</td>\n",
       "      <td>0.001987</td>\n",
       "      <td>0.000054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>162.627871</td>\n",
       "      <td>4.848843</td>\n",
       "      <td>0.720803</td>\n",
       "      <td>0.998370</td>\n",
       "      <td>gini</td>\n",
       "      <td>1000</td>\n",
       "      <td>{u'n_estimators': 1000, u'criterion': u'gini'}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.724020</td>\n",
       "      <td>0.998336</td>\n",
       "      <td>...</td>\n",
       "      <td>0.718792</td>\n",
       "      <td>0.998375</td>\n",
       "      <td>0.717275</td>\n",
       "      <td>0.998449</td>\n",
       "      <td>0.721490</td>\n",
       "      <td>0.998279</td>\n",
       "      <td>0.375315</td>\n",
       "      <td>0.137271</td>\n",
       "      <td>0.002449</td>\n",
       "      <td>0.000058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.782155</td>\n",
       "      <td>0.054417</td>\n",
       "      <td>0.691084</td>\n",
       "      <td>0.994617</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>{u'n_estimators': 10, u'criterion': u'entropy'}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.692590</td>\n",
       "      <td>0.994703</td>\n",
       "      <td>...</td>\n",
       "      <td>0.689275</td>\n",
       "      <td>0.994766</td>\n",
       "      <td>0.682015</td>\n",
       "      <td>0.994733</td>\n",
       "      <td>0.694325</td>\n",
       "      <td>0.994427</td>\n",
       "      <td>0.012345</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.005213</td>\n",
       "      <td>0.000145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.340593</td>\n",
       "      <td>0.484173</td>\n",
       "      <td>0.718189</td>\n",
       "      <td>0.998197</td>\n",
       "      <td>entropy</td>\n",
       "      <td>100</td>\n",
       "      <td>{u'n_estimators': 100, u'criterion': u'entropy'}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.720759</td>\n",
       "      <td>0.998153</td>\n",
       "      <td>...</td>\n",
       "      <td>0.715221</td>\n",
       "      <td>0.998189</td>\n",
       "      <td>0.715468</td>\n",
       "      <td>0.998289</td>\n",
       "      <td>0.718351</td>\n",
       "      <td>0.998103</td>\n",
       "      <td>0.214264</td>\n",
       "      <td>0.001699</td>\n",
       "      <td>0.002514</td>\n",
       "      <td>0.000066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>174.784947</td>\n",
       "      <td>4.881357</td>\n",
       "      <td>0.721179</td>\n",
       "      <td>0.998365</td>\n",
       "      <td>entropy</td>\n",
       "      <td>1000</td>\n",
       "      <td>{u'n_estimators': 1000, u'criterion': u'entropy'}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.723949</td>\n",
       "      <td>0.998334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.719576</td>\n",
       "      <td>0.998360</td>\n",
       "      <td>0.717684</td>\n",
       "      <td>0.998438</td>\n",
       "      <td>0.721210</td>\n",
       "      <td>0.998288</td>\n",
       "      <td>2.226279</td>\n",
       "      <td>0.171574</td>\n",
       "      <td>0.002355</td>\n",
       "      <td>0.000053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       1.665466         0.054109         0.688218          0.994487   \n",
       "1      16.232890         0.483897         0.718327          0.998192   \n",
       "2     162.627871         4.848843         0.720803          0.998370   \n",
       "3       1.782155         0.054417         0.691084          0.994617   \n",
       "4      17.340593         0.484173         0.718189          0.998197   \n",
       "5     174.784947         4.881357         0.721179          0.998365   \n",
       "\n",
       "  param_criterion param_n_estimators  \\\n",
       "0            gini                 10   \n",
       "1            gini                100   \n",
       "2            gini               1000   \n",
       "3         entropy                 10   \n",
       "4         entropy                100   \n",
       "5         entropy               1000   \n",
       "\n",
       "                                              params  rank_test_score  \\\n",
       "0       {u'n_estimators': 10, u'criterion': u'gini'}                6   \n",
       "1      {u'n_estimators': 100, u'criterion': u'gini'}                3   \n",
       "2     {u'n_estimators': 1000, u'criterion': u'gini'}                2   \n",
       "3    {u'n_estimators': 10, u'criterion': u'entropy'}                5   \n",
       "4   {u'n_estimators': 100, u'criterion': u'entropy'}                4   \n",
       "5  {u'n_estimators': 1000, u'criterion': u'entropy'}                1   \n",
       "\n",
       "   split0_test_score  split0_train_score       ...         split2_test_score  \\\n",
       "0           0.688483            0.994330       ...                  0.688704   \n",
       "1           0.719425            0.998143       ...                  0.716627   \n",
       "2           0.724020            0.998336       ...                  0.718792   \n",
       "3           0.692590            0.994703       ...                  0.689275   \n",
       "4           0.720759            0.998153       ...                  0.715221   \n",
       "5           0.723949            0.998334       ...                  0.719576   \n",
       "\n",
       "   split2_train_score  split3_test_score  split3_train_score  \\\n",
       "0            0.994383           0.685547            0.994665   \n",
       "1            0.998194           0.715484            0.998244   \n",
       "2            0.998375           0.717275            0.998449   \n",
       "3            0.994766           0.682015            0.994733   \n",
       "4            0.998189           0.715468            0.998289   \n",
       "5            0.998360           0.717684            0.998438   \n",
       "\n",
       "   split4_test_score  split4_train_score  std_fit_time  std_score_time  \\\n",
       "0           0.683818            0.994449      0.019514        0.000617   \n",
       "1           0.719147            0.998120      0.121571        0.006928   \n",
       "2           0.721490            0.998279      0.375315        0.137271   \n",
       "3           0.694325            0.994427      0.012345        0.000204   \n",
       "4           0.718351            0.998103      0.214264        0.001699   \n",
       "5           0.721210            0.998288      2.226279        0.171574   \n",
       "\n",
       "   std_test_score  std_train_score  \n",
       "0        0.003654         0.000129  \n",
       "1        0.001987         0.000054  \n",
       "2        0.002449         0.000058  \n",
       "3        0.005213         0.000145  \n",
       "4        0.002514         0.000066  \n",
       "5        0.002355         0.000053  \n",
       "\n",
       "[6 rows x 22 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gd1.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ 0.73091097  0.72409425  0.72164424  0.7293044   0.72186764  0.72116273\n",
      "  0.72410289  0.71568915  0.72732834  0.7158548 ]\n"
     ]
    }
   ],
   "source": [
    "scores_ranfor = cross_val_score(RandomForestClassifier(n_estimators=1000,criterion='entropy'), train_X, train_y, cv=10, scoring='roc_auc')\n",
    "print ''\n",
    "print scores_ranfor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About a 3-4% improvement in using more trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM with Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Equation looks like = sum (1-y*(w*x+b)) + lambda*w^2\n",
    "#\n",
    "# initialize model parameters w and b\n",
    "# intializing to 0 is not a good idea\n",
    "# it should be a random vector see np.random.randn\n",
    "# YOU NEED TO IMPLEMENT THIS\n",
    "def _initialize_parameters(nfeatures):\n",
    "    w = np.random.randn((nfeatures))\n",
    "    b = 0#np.random.rand(1)\n",
    "    return w, b\n",
    "\n",
    "# this is a vectorized version of positive_part operation\n",
    "# we can use this for hinge loss as post_part(1.0 - y*f)\n",
    "pos_part = np.vectorize(lambda u: u if u > 0. else 0.)\n",
    "\n",
    "# compute the value of the linear SVM objective function\n",
    "# given current signed distances, and parameter vector w\n",
    "def _get_objective(f, y, w, lam):\n",
    "    loss = np.sum(pos_part(1.0 - y*f))\n",
    "    penalty = lam * np.dot(w,w)\n",
    "    return loss + penalty\n",
    "\n",
    "# compute the signed distances\n",
    "# based on current model estimates\n",
    "# w and b\n",
    "# YOU NEED TO IMPLEMENT THIS\n",
    "def _get_signed_distances(X, w, b):\n",
    "    nobs = X.shape[0]\n",
    "    f = np.full(nobs, 0.0)\n",
    "    for i,obs in enumerate(X):\n",
    "        f[i] = b + np.dot(obs,w)\n",
    "    return f\n",
    "\n",
    "# compute gradients with respect to w and b\n",
    "# YOU NEEED TO IMPLEMENT THIS\n",
    "\n",
    "def _get_gradients(f, X, y, w, b, lam):\n",
    "    gb = np.sum(-1*y)\n",
    "    gw = np.zeros(w.shape)\n",
    "    for y1,obs in zip(y,X):\n",
    "        gw += -1*obs*y1\n",
    "    gw += 2*lam*w\n",
    "    return gw, gb\n",
    "\n",
    "# fit an SVM using gradient descent\n",
    "# X: matrix of feature values\n",
    "# y: labels (-1 or 1)\n",
    "# lam: penalty parameter lambda\n",
    "# n_iter: numer of iterations\n",
    "# eta: learning rate\n",
    "def fit_svm(X, y, lam, n_iter=100, eta=.4):\n",
    "    nexamples, nfeatures = X.shape\n",
    "    \n",
    "    w, b = _initialize_parameters(nfeatures)\n",
    "    \n",
    "    for k in range(n_iter):\n",
    "        f = _get_signed_distances(X, w, b)\n",
    "        \n",
    "        # print information and \n",
    "        # update the learning rate\n",
    "        if k % 10 == 0:\n",
    "            obj = _get_objective(f, y, w, lam)\n",
    "            eta = eta / 2.0\n",
    "            print(\"it: %d, obj %.2f\" % (k, obj))\n",
    "        \n",
    "        gw, gb = _get_gradients(f, X, y, w, b, lam)\n",
    "        w = w - eta * gw\n",
    "        b = b - eta * gb\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it: 0, obj 176934.46\n",
      "it: 10, obj 3724833172.83\n",
      "it: 20, obj 4726749739.43\n",
      "it: 30, obj 5221209644.65\n",
      "it: 40, obj 5468094381.32\n",
      "it: 50, obj 5591493508.10\n",
      "it: 60, obj 5653185280.22\n",
      "it: 70, obj 5684029505.77\n",
      "it: 80, obj 5699451234.87\n",
      "it: 90, obj 5707162007.18\n"
     ]
    }
   ],
   "source": [
    "w,b = fit_svm(train_X, train_y, 1.0, n_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
